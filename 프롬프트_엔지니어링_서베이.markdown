# 프롬프트 엔지니어링 서베이

논문 링크: https://arxiv.org/pdf/2402.07927

**이 논문을 읽는 이유?**
  LLM을 나의 의도대로 사용하기 위한 방법으로, 어떤 것들이 있는지 확인하기 위해, 이 논문을 읽게됐음. GraphRAG 연구를 하면서,   색인/검색 과정 모두 프롬프트에 상당히 의존하고 있어서, 프롬프트 엔지니어링 역량이 매우 중요하다. 내용보고 좀 더 조사하거나 코멘트를 아래에 기록

## training 없이, 새로운 task를 수행하기 위한 방법

**Zero-shot prompting**
  별도의 지도 없이, 단순히 프롬프트 안에 LLM이 수행할 task를 기술하는 방법

- 간단한 task 
- 명료한, 보편적인 task e.g. 문법 검사
- few-shot 또는 fine-tuning을 적용하기 어려울 때

하지만, task가 복잡하거나, 애매모호한 경우 이 방법을 사용한다면, 우리가 원하는 결과를 보장 할 수 없다.

**Few-shot prompting**
  프롬프트 안에 task 예제들을 포함하는 방법. 예제가 있다는 점에서 zero-shot prompting과 다르며, 상대적으로 복잡한 task에서 사용 할 수 있다. 주의사항이 있다면, 예제를 사용한다는 것은 토큰을 추가적으로 사용하는 것이기 때문에, 비용 증가와 편향 이슈가 있다. 후자가 상당히 골 때리므로, 예제를 정성스럽게 작성하는 것을 권장한다.



## 추론과 논리가 있는 task를 수행하기 위한 방법

**Chain-of-Thought(CoT) prompting**
  복잡한 논리가 있는 task를 수행하기 위해, 프롬프트 안에 일관적이고 단계별 절차를 기술하는 방법. 예를들어 수학 문제를 LLM을 통해 해결하고자 할 때, 이 방법을 사용하면 유용하다. 하지만 LLM이 틀린 논리를 그럴듯하게 생성하는 경우가 있으므로, LLM의 추론 과정을 점검할 필요가 있다.

**Automatic Chain-of-Thought prompting**
  기존 CoT + 프롬프트 안에, 추론 체인을 생성하는 내용을 기술하는 방법. 높은 품질의 CoT 예제를 사람 손으로 생성하는 것은 시간이 오래 걸리고, 편향 가능성이 있음. 따라서 이를 보완한다고 하는데, 결과를 보면 평균적으로 arithmetic에서 1.33% 향상, symbolic reasoning에서 1.5% 향상이 있다고함. 기존 방법 결과와 미세한 차이라서 구체적인 방법론은 기술하지 않는다.

**Self-Consistency**
  다양한 추론 체인을 생성하고 여기서 나오는 결과들 중, 가장 적합한 결과를 식별하는 방법. 깊은 사고력을 요구하는 문제를 해결하기 위해, 다양한 추론 방법을 수반하는데, 이 방법으로 접근하면 해결 할 수 있다. 이 방법은 CoT 프롬프팅 기법에 사용되는오직 하나의 추론 체인만 선택하는 `naive greedy decoding`를 대체한다. 여러 벤치마크 데이터셋에서 baseline CoT보다 더 나은 성능을 보여준다.

참고. Self-consistency 활용 예제: https://www.promptingguide.ai/kr/techniques/consistency

**Logical Chain-of-Thought(LogiCoT) prompting**
   `모순에 의한 반증의 개념`을 적용하여 모델이 생성한 각 추론 단계를 검증하고, 잘못된 단계를 수정하기 위한 목표 피드백을 제공하는 방법. 기존의 CoT는 추론 단계에 대한 검증 능력이 부족한데, 이 연구는 이를 보완한다. 근데 기존 결과와 차이가 그렇게 크지 않음











